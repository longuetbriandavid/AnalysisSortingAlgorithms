# AnalysisSortingAlgorithms

**Context : **

Le tri de données est une opération fondamentale dans l’informatique, qui consiste à organiser un ensemble de données dans un ordre précis. Il existe de nombreux algorithmes de tri, chacun ayant ses avantages et ses inconvénients. Certains algorithmes sont plus efficaces que d’autres en fonction de la structure des données à trier, et certains peuvent même être optimisés en fonction de la distribution des données en entrée.


L’objectif de ce projet est d’implémenter une collection d’algorithmes de tri et de les visualiser en action. Mais au-delà de cet aspect pratique, nous pouvons également nous intéresser à l’efficacité de ces algorithmes en fonction du niveau de désordre des données en entrée. En effet, le nombre de comparaisons, les accès aux données et le temps d’exécution total d’un algorithme peuvent varier considérablement en fonction de la quantité et de la répartition des données à trier.


Pour répondre à cette question, nous avons dû développer un générateur de
données paramétré par un niveau de désordre, et effectuer des expériences pour
comparer les performances des différents algorithmes de tri en fonction de ce paramètre. En analysant les résultats, nous avons déterminé quels algorithmes sont les plus adaptés à des situations de désordre élevé ou faible.





**Mode d'emploi : **

En raison de contraintes de temps, nous n'avons pas pu intégrer ma partie "Visualisation des algorithmes de tri pas à pas" au reste du projet. Pour l'utiliser, il vous suffit d'exécuter le fichier main.py en utilisant la commande **python3 main.py**.

Pour découvrir le reste du projet, veuillez lancer la commande **python3 tkMain.py**.

Pour plus d'informations, veuillez consulter le rapport "**Rapport_Projet-3.pdf**" situé dans le dossier rapport.
